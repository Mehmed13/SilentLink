{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:22:26.001691Z",
     "iopub.status.busy": "2024-12-11T15:22:26.000887Z",
     "iopub.status.idle": "2024-12-11T15:22:44.670325Z",
     "shell.execute_reply": "2024-12-11T15:22:44.669617Z",
     "shell.execute_reply.started": "2024-12-11T15:22:26.001653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, TFBertModel\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Input\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:22:44.672410Z",
     "iopub.status.busy": "2024-12-11T15:22:44.671875Z",
     "iopub.status.idle": "2024-12-11T15:22:45.724387Z",
     "shell.execute_reply": "2024-12-11T15:22:45.723265Z",
     "shell.execute_reply.started": "2024-12-11T15:22:44.672375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:22:45.725984Z",
     "iopub.status.busy": "2024-12-11T15:22:45.725683Z",
     "iopub.status.idle": "2024-12-11T15:22:46.500293Z",
     "shell.execute_reply": "2024-12-11T15:22:46.499407Z",
     "shell.execute_reply.started": "2024-12-11T15:22:45.725956Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_category</th>\n",
       "      <th>original_text</th>\n",
       "      <th>base_word_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>what makes friendship click?</td>\n",
       "      <td>what make friendship click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>why does zebras have stripes?</td>\n",
       "      <td>why zebra stripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>what did the itsy bitsy sipder climb up?</td>\n",
       "      <td>what itsy bitsy sipder climb up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>what is the difference between a bachelors and...</td>\n",
       "      <td>what difference between bachelor and master de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>why do women get pms?</td>\n",
       "      <td>why woman get pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174712</th>\n",
       "      <td>9.0</td>\n",
       "      <td>imperative: tell me what guys only guys must do!</td>\n",
       "      <td>tell me what guy only guy must</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174713</th>\n",
       "      <td>9.0</td>\n",
       "      <td>tell me the story of any fantasy figure i'd ch...</td>\n",
       "      <td>tell me story of any fantasy figure i d choose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174714</th>\n",
       "      <td>8.0</td>\n",
       "      <td>imperative: reveal a secret about life.</td>\n",
       "      <td>reveal secret about life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174715</th>\n",
       "      <td>6.0</td>\n",
       "      <td>imperative: demande à domenech ce qu'il en est...</td>\n",
       "      <td>demande à domenech ce quil en est de son méti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174716</th>\n",
       "      <td>5.0</td>\n",
       "      <td>tell me the low sounds that a cat makes!</td>\n",
       "      <td>tell me low sound that cat make</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174717 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic_category                                      original_text  \\\n",
       "0                  9.0                       what makes friendship click?   \n",
       "1                  2.0                      why does zebras have stripes?   \n",
       "2                  4.0           what did the itsy bitsy sipder climb up?   \n",
       "3                  4.0  what is the difference between a bachelors and...   \n",
       "4                  3.0                              why do women get pms?   \n",
       "...                ...                                                ...   \n",
       "174712             9.0  imperative: tell me what guys only guys must do!    \n",
       "174713             9.0  tell me the story of any fantasy figure i'd ch...   \n",
       "174714             8.0           imperative: reveal a secret about life.    \n",
       "174715             6.0  imperative: demande à domenech ce qu'il en est...   \n",
       "174716             5.0          tell me the low sounds that a cat makes!    \n",
       "\n",
       "                                           base_word_text  \n",
       "0                             what make friendship click   \n",
       "1                                       why zebra stripe   \n",
       "2                        what itsy bitsy sipder climb up   \n",
       "3       what difference between bachelor and master de...  \n",
       "4                                       why woman get pm   \n",
       "...                                                   ...  \n",
       "174712                    tell me what guy only guy must   \n",
       "174713    tell me story of any fantasy figure i d choose   \n",
       "174714                          reveal secret about life   \n",
       "174715   demande à domenech ce quil en est de son méti...  \n",
       "174716                   tell me low sound that cat make   \n",
       "\n",
       "[174717 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/tubes-nlp/seq2seq_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:22:46.503406Z",
     "iopub.status.busy": "2024-12-11T15:22:46.502596Z",
     "iopub.status.idle": "2024-12-11T15:22:46.554932Z",
     "shell.execute_reply": "2024-12-11T15:22:46.554060Z",
     "shell.execute_reply.started": "2024-12-11T15:22:46.503359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_category    0\n",
       "original_text     0\n",
       "base_word_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:22:46.557012Z",
     "iopub.status.busy": "2024-12-11T15:22:46.556240Z",
     "iopub.status.idle": "2024-12-11T15:23:03.507746Z",
     "shell.execute_reply": "2024-12-11T15:23:03.506848Z",
     "shell.execute_reply.started": "2024-12-11T15:22:46.556950Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what makes friendship click?</td>\n",
       "      <td>makes friendship click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why does zebras have stripes?</td>\n",
       "      <td>zebras stripes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did the itsy bitsy sipder climb up?</td>\n",
       "      <td>itsy bitsy sipder climb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the difference between a bachelors and...</td>\n",
       "      <td>difference bachelors masters degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why do women get pms?</td>\n",
       "      <td>women get pms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0                       what makes friendship click?   \n",
       "1                      why does zebras have stripes?   \n",
       "2           what did the itsy bitsy sipder climb up?   \n",
       "3  what is the difference between a bachelors and...   \n",
       "4                              why do women get pms?   \n",
       "\n",
       "                        processed_text  \n",
       "0               makes friendship click  \n",
       "1                       zebras stripes  \n",
       "2              itsy bitsy sipder climb  \n",
       "3  difference bachelors masters degree  \n",
       "4                        women get pms  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update([\"imperative\", \"declarative\"])\n",
    "punctuation = string.punctuation\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', punctuation))\n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to the 'original_text' column\n",
    "data['processed_text'] = data['original_text'].apply(preprocess_text)\n",
    "data[['original_text', 'processed_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:01:44.987418Z",
     "iopub.status.busy": "2024-12-10T03:01:44.986295Z",
     "iopub.status.idle": "2024-12-10T03:01:48.993422Z",
     "shell.execute_reply": "2024-12-10T03:01:48.992664Z",
     "shell.execute_reply.started": "2024-12-10T03:01:44.987381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['processed_text'])\n",
    "X = tokenizer.texts_to_sequences(data['processed_text'])\n",
    "X = pad_sequences(X, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:01:48.995363Z",
     "iopub.status.busy": "2024-12-10T03:01:48.994990Z",
     "iopub.status.idle": "2024-12-10T03:01:59.170063Z",
     "shell.execute_reply": "2024-12-10T03:01:59.169364Z",
     "shell.execute_reply.started": "2024-12-10T03:01:48.995327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained GloVe embeddings\n",
    "embedding_index = {}\n",
    "with open('/kaggle/input/tubes-nlp/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:01:59.171533Z",
     "iopub.status.busy": "2024-12-10T03:01:59.171271Z",
     "iopub.status.idle": "2024-12-10T03:01:59.194901Z",
     "shell.execute_reply": "2024-12-10T03:01:59.194276Z",
     "shell.execute_reply.started": "2024-12-10T03:01:59.171506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((5000, 100))\n",
    "for word, i in word_index.items():\n",
    "    if i < 5000:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:23:08.444688Z",
     "iopub.status.busy": "2024-12-11T15:23:08.444356Z",
     "iopub.status.idle": "2024-12-11T15:23:10.119864Z",
     "shell.execute_reply": "2024-12-11T15:23:10.118920Z",
     "shell.execute_reply.started": "2024-12-11T15:23:08.444660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer_bert_embedding = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_embedding_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:23:10.121688Z",
     "iopub.status.busy": "2024-12-11T15:23:10.121429Z",
     "iopub.status.idle": "2024-12-11T15:41:56.515010Z",
     "shell.execute_reply": "2024-12-11T15:41:56.514081Z",
     "shell.execute_reply.started": "2024-12-11T15:23:10.121662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5797/5797 [18:46<00:00,  5.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input text\n",
    "\n",
    "chunk_size = 30  \n",
    "texts = list(data['processed_text'])\n",
    "num_chunks = (len(texts)) // chunk_size + 1\n",
    "\n",
    "all_embeddings = []\n",
    "for chunk_idx in tqdm(range(num_chunks)):\n",
    "    chunk_texts = texts[chunk_idx * chunk_size:(chunk_idx + 1) * chunk_size]\n",
    "    inputs = tokenizer_bert_embedding(chunk_texts, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = bert_embedding_model(**inputs)\n",
    "    all_embeddings.append(outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:54:01.749448Z",
     "iopub.status.busy": "2024-12-11T12:54:01.749098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:01:28.413272Z",
     "iopub.status.busy": "2024-12-11T13:01:28.412884Z",
     "iopub.status.idle": "2024-12-11T13:01:28.760758Z",
     "shell.execute_reply": "2024-12-11T13:01:28.760098Z",
     "shell.execute_reply.started": "2024-12-11T13:01:28.413242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## BERT\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:01:29.191598Z",
     "iopub.status.busy": "2024-12-11T13:01:29.191274Z",
     "iopub.status.idle": "2024-12-11T13:01:29.198493Z",
     "shell.execute_reply": "2024-12-11T13:01:29.197585Z",
     "shell.execute_reply.started": "2024-12-11T13:01:29.191570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TopicClassificationDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for topic classification\"\"\"\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Handle both integer and list indexing\n",
    "        if isinstance(idx, list):\n",
    "            texts = [self.texts[i] for i in idx]\n",
    "            labels = [self.labels[i] for i in idx]\n",
    "        else:\n",
    "            texts = [self.texts[idx]]\n",
    "            labels = [self.labels[idx]]\n",
    "        \n",
    "        # Batch encoding\n",
    "        encodings = self.tokenizer(\n",
    "            texts,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encodings['input_ids'].squeeze(),\n",
    "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long).squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:42:52.142275Z",
     "iopub.status.busy": "2024-12-11T15:42:52.141356Z",
     "iopub.status.idle": "2024-12-11T15:42:52.200036Z",
     "shell.execute_reply": "2024-12-11T15:42:52.199117Z",
     "shell.execute_reply.started": "2024-12-11T15:42:52.142235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical([label - 1 for label in data['topic_category'].values], num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T05:25:27.647731Z",
     "iopub.status.busy": "2024-12-10T05:25:27.647332Z",
     "iopub.status.idle": "2024-12-10T05:25:27.652167Z",
     "shell.execute_reply": "2024-12-10T05:25:27.651289Z",
     "shell.execute_reply.started": "2024-12-10T05:25:27.647700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:42:54.909232Z",
     "iopub.status.busy": "2024-12-11T15:42:54.908858Z",
     "iopub.status.idle": "2024-12-11T15:42:54.916382Z",
     "shell.execute_reply": "2024-12-11T15:42:54.915389Z",
     "shell.execute_reply.started": "2024-12-11T15:42:54.909200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_bert_embedding = [y[chunk_idx * chunk_size:(chunk_idx + 1) * chunk_size] for chunk_idx in range (num_chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:42:56.054705Z",
     "iopub.status.busy": "2024-12-11T15:42:56.054324Z",
     "iopub.status.idle": "2024-12-11T15:42:56.059717Z",
     "shell.execute_reply": "2024-12-11T15:42:56.058837Z",
     "shell.execute_reply.started": "2024-12-11T15:42:56.054672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "split_idx = int(num_chunks * 0.8) \n",
    "\n",
    "X_train_bert_embedding, X_test_bert_embedding = all_embeddings[:split_idx], all_embeddings[split_idx:-1]\n",
    "y_train_bert_embedding, y_test_bert_embedding = y_bert_embedding[:split_idx], y_bert_embedding[split_idx:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:01:34.731844Z",
     "iopub.status.busy": "2024-12-11T13:01:34.731461Z",
     "iopub.status.idle": "2024-12-11T13:01:34.803018Z",
     "shell.execute_reply": "2024-12-11T13:01:34.802000Z",
     "shell.execute_reply.started": "2024-12-11T13:01:34.731813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_category\n",
      "1.0     869\n",
      "2.0     869\n",
      "3.0     869\n",
      "4.0     869\n",
      "5.0     869\n",
      "6.0     869\n",
      "7.0     869\n",
      "8.0     869\n",
      "9.0     869\n",
      "10.0    869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sample_ratio = 0.05  \n",
    "instances_per_class = int(len(data) * sample_ratio / 10)  # Calculate instances per class\n",
    "\n",
    "# Sample data equally for each class\n",
    "sample_data = data.groupby('topic_category').sample(n=instances_per_class, random_state=42)\n",
    "\n",
    "# Ensure balanced test set\n",
    "print(sample_data['topic_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:02:07.328581Z",
     "iopub.status.busy": "2024-12-11T13:02:07.327812Z",
     "iopub.status.idle": "2024-12-11T13:02:07.341877Z",
     "shell.execute_reply": "2024-12-11T13:02:07.340878Z",
     "shell.execute_reply.started": "2024-12-11T13:02:07.328546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(list(sample_data['processed_text']), [int(label - 1) for label in sample_data['topic_category'].values], test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:02:15.726528Z",
     "iopub.status.busy": "2024-12-11T13:02:15.726164Z",
     "iopub.status.idle": "2024-12-11T13:02:15.732027Z",
     "shell.execute_reply": "2024-12-11T13:02:15.731014Z",
     "shell.execute_reply.started": "2024-12-11T13:02:15.726499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = TopicClassificationDataset(X_train_bert, y_train_bert, bert_tokenizer)\n",
    "val_dataset = TopicClassificationDataset(X_test_bert, y_test_bert, bert_tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:08:19.438309Z",
     "iopub.status.busy": "2024-12-10T03:08:19.437865Z",
     "iopub.status.idle": "2024-12-10T03:08:19.469353Z",
     "shell.execute_reply": "2024-12-10T03:08:19.468468Z",
     "shell.execute_reply.started": "2024-12-10T03:08:19.438277Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=5000, output_dim=100, weights=[embedding_matrix], input_length=100, trainable=False))\n",
    "lstm_model.add(Bidirectional(tf.keras.layers.LSTM(200)))\n",
    "lstm_model.add(Dense(100, activation='relu'))\n",
    "lstm_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:08:19.737405Z",
     "iopub.status.busy": "2024-12-10T03:08:19.737045Z",
     "iopub.status.idle": "2024-12-10T03:14:28.777590Z",
     "shell.execute_reply": "2024-12-10T03:14:28.776760Z",
     "shell.execute_reply.started": "2024-12-10T03:08:19.737376Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2174/2174 - 39s - 18ms/step - accuracy: 0.5550 - loss: 1.3731 - val_accuracy: 0.5772 - val_loss: 1.3020\n",
      "Epoch 2/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.5917 - loss: 1.2566 - val_accuracy: 0.5907 - val_loss: 1.2625\n",
      "Epoch 3/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.6076 - loss: 1.2044 - val_accuracy: 0.5987 - val_loss: 1.2410\n",
      "Epoch 4/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.6252 - loss: 1.1439 - val_accuracy: 0.6004 - val_loss: 1.2390\n",
      "Epoch 5/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.6409 - loss: 1.0922 - val_accuracy: 0.6041 - val_loss: 1.2291\n",
      "Epoch 6/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.6566 - loss: 1.0356 - val_accuracy: 0.6051 - val_loss: 1.2451\n",
      "Epoch 7/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.6757 - loss: 0.9729 - val_accuracy: 0.6039 - val_loss: 1.2592\n",
      "Epoch 8/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.6944 - loss: 0.9114 - val_accuracy: 0.5998 - val_loss: 1.2902\n",
      "Epoch 9/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.7145 - loss: 0.8467 - val_accuracy: 0.5987 - val_loss: 1.3501\n",
      "Epoch 10/10\n",
      "2174/2174 - 37s - 17ms/step - accuracy: 0.7356 - loss: 0.7810 - val_accuracy: 0.5970 - val_loss: 1.4189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f79ac51eec0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM using BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:43:05.359826Z",
     "iopub.status.busy": "2024-12-11T15:43:05.359113Z",
     "iopub.status.idle": "2024-12-11T15:43:05.551039Z",
     "shell.execute_reply": "2024-12-11T15:43:05.550335Z",
     "shell.execute_reply.started": "2024-12-11T15:43:05.359791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lstm_model_bert = Sequential()\n",
    "lstm_model_bert.add(Input(shape=(None, 768))) # 768 is the hidden size of BERT-base\n",
    "lstm_model_bert.add(Bidirectional(tf.keras.layers.LSTM(200)))\n",
    "lstm_model_bert.add(Dense(100, activation='relu'))\n",
    "lstm_model_bert.add(Dense(10, activation='softmax'))\n",
    "\n",
    "lstm_model_bert.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:43:05.827080Z",
     "iopub.status.busy": "2024-12-11T15:43:05.826736Z",
     "iopub.status.idle": "2024-12-11T15:44:32.186880Z",
     "shell.execute_reply": "2024-12-11T15:44:32.185842Z",
     "shell.execute_reply.started": "2024-12-11T15:43:05.827047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 - 34s - 34s/step - accuracy: 0.0333 - loss: 2.3634 - val_accuracy: 0.0667 - val_loss: 2.3802\n",
      "Epoch 2/2\n",
      "1/1 - 18s - 18s/step - accuracy: 0.6667 - loss: 1.8155 - val_accuracy: 0.1000 - val_loss: 2.4250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7cfb96046a10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model_bert.fit(X_train_bert_embedding, y_train_bert_embedding, epochs=2, batch_size=chunk_size, validation_data=(X_test_bert_embedding, y_test_bert_embedding), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:06:22.781178Z",
     "iopub.status.busy": "2024-12-10T03:06:22.780804Z",
     "iopub.status.idle": "2024-12-10T03:06:22.797596Z",
     "shell.execute_reply": "2024-12-10T03:06:22.796868Z",
     "shell.execute_reply.started": "2024-12-10T03:06:22.781146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=5000, output_dim=100, input_length=100))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:06:23.018023Z",
     "iopub.status.busy": "2024-12-10T03:06:23.017446Z",
     "iopub.status.idle": "2024-12-10T03:07:29.422907Z",
     "shell.execute_reply": "2024-12-10T03:07:29.422074Z",
     "shell.execute_reply.started": "2024-12-10T03:06:23.017994Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2174/2174 - 11s - 5ms/step - accuracy: 0.5028 - loss: 1.5549 - val_accuracy: 0.5926 - val_loss: 1.2849\n",
      "Epoch 2/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.6032 - loss: 1.2847 - val_accuracy: 0.6032 - val_loss: 1.2405\n",
      "Epoch 3/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.6289 - loss: 1.1874 - val_accuracy: 0.6057 - val_loss: 1.2377\n",
      "Epoch 4/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.6536 - loss: 1.0931 - val_accuracy: 0.6076 - val_loss: 1.2426\n",
      "Epoch 5/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.6798 - loss: 1.0028 - val_accuracy: 0.6060 - val_loss: 1.2719\n",
      "Epoch 6/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.7055 - loss: 0.9130 - val_accuracy: 0.6043 - val_loss: 1.3517\n",
      "Epoch 7/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.7288 - loss: 0.8282 - val_accuracy: 0.6004 - val_loss: 1.4379\n",
      "Epoch 8/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.7505 - loss: 0.7557 - val_accuracy: 0.5974 - val_loss: 1.5291\n",
      "Epoch 9/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.7678 - loss: 0.6999 - val_accuracy: 0.5939 - val_loss: 1.6744\n",
      "Epoch 10/10\n",
      "2174/2174 - 6s - 3ms/step - accuracy: 0.7819 - loss: 0.6510 - val_accuracy: 0.5936 - val_loss: 1.7490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f79c02f0040>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:02:32.076701Z",
     "iopub.status.busy": "2024-12-11T13:02:32.076350Z",
     "iopub.status.idle": "2024-12-11T13:02:32.438959Z",
     "shell.execute_reply": "2024-12-11T13:02:32.437811Z",
     "shell.execute_reply.started": "2024-12-11T13:02:32.076671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:02:36.524922Z",
     "iopub.status.busy": "2024-12-11T13:02:36.524560Z",
     "iopub.status.idle": "2024-12-11T13:02:36.529269Z",
     "shell.execute_reply": "2024-12-11T13:02:36.528365Z",
     "shell.execute_reply.started": "2024-12-11T13:02:36.524892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bert_model.config.problem_type = \"single_label_classification\"  # For multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:02:37.227796Z",
     "iopub.status.busy": "2024-12-11T13:02:37.227488Z",
     "iopub.status.idle": "2024-12-11T13:02:37.237260Z",
     "shell.execute_reply": "2024-12-11T13:02:37.236282Z",
     "shell.execute_reply.started": "2024-12-11T13:02:37.227770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(bert_model.parameters(), lr=2e-5)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:02:39.553389Z",
     "iopub.status.busy": "2024-12-11T13:02:39.553026Z",
     "iopub.status.idle": "2024-12-11T13:02:39.559158Z",
     "shell.execute_reply": "2024-12-11T13:02:39.558248Z",
     "shell.execute_reply.started": "2024-12-11T13:02:39.553361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:02:42.227583Z",
     "iopub.status.busy": "2024-12-11T13:02:42.227212Z",
     "iopub.status.idle": "2024-12-11T13:11:34.679108Z",
     "shell.execute_reply": "2024-12-11T13:11:34.678135Z",
     "shell.execute_reply.started": "2024-12-11T13:02:42.227552Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Average training loss: 1.5310\n",
      "Average validation loss: 1.2267\n",
      "Epoch 2/3\n",
      "Average training loss: 1.0109\n",
      "Average validation loss: 1.2376\n",
      "Epoch 3/3\n",
      "Average training loss: 0.7431\n",
      "Average validation loss: 1.2922\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    bert_model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    bert_model.eval()\n",
    "    total_val_loss = 0\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j,batch in enumerate(val_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = bert_model(\n",
    "                input_ids, \n",
    "                attention_mask=attention_mask, \n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_val_loss += outputs.loss.item()\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Print epoch summary\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    print(f'Average training loss: {avg_train_loss:.4f}')\n",
    "    print(f'Average validation loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lstm_predictions = lstm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:16:15.604531Z",
     "iopub.status.busy": "2024-12-10T03:16:15.604276Z",
     "iopub.status.idle": "2024-12-10T03:16:15.612873Z",
     "shell.execute_reply": "2024-12-10T03:16:15.612170Z",
     "shell.execute_reply.started": "2024-12-10T03:16:15.604507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_predictions_processed = np.zeros_like(lstm_predictions)\n",
    "lstm_predictions_processed[np.arange(len(lstm_predictions)), np.argmax(lstm_predictions, axis=1)] = 1\n",
    "lstm_predictions_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:16:15.614071Z",
     "iopub.status.busy": "2024-12-10T03:16:15.613819Z",
     "iopub.status.idle": "2024-12-10T03:16:15.673787Z",
     "shell.execute_reply": "2024-12-10T03:16:15.672927Z",
     "shell.execute_reply.started": "2024-12-10T03:16:15.614046Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.45      0.48      3408\n",
      "           1       0.52      0.66      0.58      3585\n",
      "           2       0.63      0.64      0.64      3403\n",
      "           3       0.46      0.43      0.44      3523\n",
      "           4       0.76      0.76      0.76      3517\n",
      "           5       0.78      0.72      0.75      3530\n",
      "           6       0.56      0.40      0.47      3469\n",
      "           7       0.55      0.59      0.57      3538\n",
      "           8       0.57      0.64      0.61      3358\n",
      "           9       0.62      0.67      0.64      3451\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     34782\n",
      "   macro avg       0.60      0.60      0.59     34782\n",
      "weighted avg       0.60      0.60      0.59     34782\n",
      " samples avg       0.60      0.60      0.60     34782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, lstm_predictions_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM using BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:09:42.687868Z",
     "iopub.status.busy": "2024-12-11T15:09:42.686871Z",
     "iopub.status.idle": "2024-12-11T15:10:53.389180Z",
     "shell.execute_reply": "2024-12-11T15:10:53.388172Z",
     "shell.execute_reply.started": "2024-12-11T15:09:42.687813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1159/1159 [01:10<00:00, 16.39it/s]\n"
     ]
    }
   ],
   "source": [
    "lstm_bert_predictions = None\n",
    "for i in tqdm(range (len(X_test_bert_embedding))):\n",
    "    lstm_bert_prediction = lstm_model_bert.predict(X_test_bert_embedding[i], verbose=0)\n",
    "    if i == 0:\n",
    "        lstm_bert_predictions = lstm_bert_prediction\n",
    "    else:\n",
    "        lstm_bert_predictions = np.vstack((lstm_bert_predictions, lstm_bert_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:10:53.391097Z",
     "iopub.status.busy": "2024-12-11T15:10:53.390796Z",
     "iopub.status.idle": "2024-12-11T15:10:53.397278Z",
     "shell.execute_reply": "2024-12-11T15:10:53.396505Z",
     "shell.execute_reply.started": "2024-12-11T15:10:53.391068Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lstm_bert_predictions_processed = np.zeros_like(lstm_bert_predictions)\n",
    "lstm_bert_predictions_processed[np.arange(len(lstm_bert_predictions)), np.argmax(lstm_bert_predictions, axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:10:53.398510Z",
     "iopub.status.busy": "2024-12-11T15:10:53.398217Z",
     "iopub.status.idle": "2024-12-11T15:10:53.556951Z",
     "shell.execute_reply": "2024-12-11T15:10:53.556215Z",
     "shell.execute_reply.started": "2024-12-11T15:10:53.398484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_test_bert_embedding_unbatch = None\n",
    "for i in range(len(y_test_bert_embedding)):\n",
    "    if i ==0:\n",
    "        y_test_bert_embedding_unbatch = y_test_bert_embedding[0]\n",
    "    else:\n",
    "        y_test_bert_embedding_unbatch = np.vstack((y_test_bert_embedding_unbatch, y_test_bert_embedding[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:10:53.558745Z",
     "iopub.status.busy": "2024-12-11T15:10:53.558454Z",
     "iopub.status.idle": "2024-12-11T15:10:53.607636Z",
     "shell.execute_reply": "2024-12-11T15:10:53.606906Z",
     "shell.execute_reply.started": "2024-12-11T15:10:53.558718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.00      0.00      3848\n",
      "           1       0.12      0.50      0.20      3478\n",
      "           2       0.17      0.51      0.25      3558\n",
      "           3       0.14      0.08      0.10      3409\n",
      "           4       0.62      0.04      0.07      3443\n",
      "           5       0.36      0.01      0.02      3832\n",
      "           6       0.12      0.17      0.15      1974\n",
      "           7       0.17      0.04      0.06      4016\n",
      "           8       0.26      0.25      0.26      3439\n",
      "           9       0.28      0.02      0.04      3773\n",
      "\n",
      "   micro avg       0.16      0.16      0.16     34770\n",
      "   macro avg       0.26      0.16      0.12     34770\n",
      "weighted avg       0.26      0.16      0.11     34770\n",
      " samples avg       0.16      0.16      0.16     34770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test_bert_embedding_unbatch, lstm_bert_predictions_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:07:50.219752Z",
     "iopub.status.busy": "2024-12-10T03:07:50.218921Z",
     "iopub.status.idle": "2024-12-10T03:07:52.492794Z",
     "shell.execute_reply": "2024-12-10T03:07:52.492058Z",
     "shell.execute_reply.started": "2024-12-10T03:07:50.219717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_predictions = cnn_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:07:52.494757Z",
     "iopub.status.busy": "2024-12-10T03:07:52.494454Z",
     "iopub.status.idle": "2024-12-10T03:07:52.503013Z",
     "shell.execute_reply": "2024-12-10T03:07:52.502276Z",
     "shell.execute_reply.started": "2024-12-10T03:07:52.494730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_predictions_processed = np.zeros_like(cnn_predictions)\n",
    "cnn_predictions_processed[np.arange(len(cnn_predictions)), np.argmax(cnn_predictions, axis=1)] = 1\n",
    "cnn_predictions_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:07:55.393694Z",
     "iopub.status.busy": "2024-12-10T03:07:55.393367Z",
     "iopub.status.idle": "2024-12-10T03:07:55.448590Z",
     "shell.execute_reply": "2024-12-10T03:07:55.447664Z",
     "shell.execute_reply.started": "2024-12-10T03:07:55.393664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.49      0.48      3408\n",
      "           1       0.52      0.64      0.57      3585\n",
      "           2       0.61      0.66      0.63      3403\n",
      "           3       0.50      0.40      0.45      3523\n",
      "           4       0.76      0.75      0.76      3517\n",
      "           5       0.80      0.71      0.75      3530\n",
      "           6       0.52      0.42      0.46      3469\n",
      "           7       0.58      0.57      0.57      3538\n",
      "           8       0.55      0.65      0.59      3358\n",
      "           9       0.64      0.65      0.65      3451\n",
      "\n",
      "   micro avg       0.59      0.59      0.59     34782\n",
      "   macro avg       0.60      0.59      0.59     34782\n",
      "weighted avg       0.60      0.59      0.59     34782\n",
      " samples avg       0.59      0.59      0.59     34782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, cnn_predictions_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:13:29.088071Z",
     "iopub.status.busy": "2024-12-11T13:13:29.087144Z",
     "iopub.status.idle": "2024-12-11T13:13:29.094024Z",
     "shell.execute_reply": "2024-12-11T13:13:29.093126Z",
     "shell.execute_reply.started": "2024-12-11T13:13:29.088031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_topic(text, model, tokenizer, max_length=128):\n",
    "    \"\"\"\n",
    "    Predict topic for a single text input\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to classify\n",
    "        model (BertForSequenceClassification): Trained BERT model\n",
    "        tokenizer (BertTokenizer): Tokenizer used during training\n",
    "        max_length (int): Maximum sequence length\n",
    "    \n",
    "    Returns:\n",
    "        Predicted topic label (integer)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Encode the text\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    return prediction.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:13:29.943577Z",
     "iopub.status.busy": "2024-12-11T13:13:29.943255Z",
     "iopub.status.idle": "2024-12-11T13:13:53.156835Z",
     "shell.execute_reply": "2024-12-11T13:13:53.155904Z",
     "shell.execute_reply.started": "2024-12-11T13:13:29.943553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:23<00:00, 74.90it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_predictions = []\n",
    "for test_text in tqdm(X_test_bert):\n",
    "        predicted_topic = predict_topic(\n",
    "            test_text, bert_model, bert_tokenizer\n",
    "        )\n",
    "        bert_predictions.append(predicted_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:13:53.158561Z",
     "iopub.status.busy": "2024-12-11T13:13:53.158267Z",
     "iopub.status.idle": "2024-12-11T13:13:53.175869Z",
     "shell.execute_reply": "2024-12-11T13:13:53.174999Z",
     "shell.execute_reply.started": "2024-12-11T13:13:53.158534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.54       184\n",
      "           1       0.61      0.66      0.64       193\n",
      "           2       0.68      0.77      0.72       160\n",
      "           3       0.50      0.31      0.38       179\n",
      "           4       0.70      0.75      0.73       158\n",
      "           5       0.80      0.77      0.79       179\n",
      "           6       0.55      0.45      0.49       167\n",
      "           7       0.63      0.62      0.63       186\n",
      "           8       0.51      0.78      0.62       167\n",
      "           9       0.69      0.67      0.68       165\n",
      "\n",
      "    accuracy                           0.63      1738\n",
      "   macro avg       0.63      0.63      0.62      1738\n",
      "weighted avg       0.63      0.63      0.62      1738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test_bert, bert_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:13:53.176931Z",
     "iopub.status.busy": "2024-12-11T13:13:53.176703Z",
     "iopub.status.idle": "2024-12-11T13:13:54.827762Z",
     "shell.execute_reply": "2024-12-11T13:13:54.826738Z",
     "shell.execute_reply.started": "2024-12-11T13:13:53.176909Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bert_model_v2/tokenizer_config.json',\n",
       " './fine_tuned_bert_model_v2/special_tokens_map.json',\n",
       " './fine_tuned_bert_model_v2/vocab.txt',\n",
       " './fine_tuned_bert_model_v2/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = './fine_tuned_bert_model_v2'\n",
    "\n",
    "bert_model.save_pretrained(save_directory)\n",
    "bert_tokenizer.save_pretrained(save_directory)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6255630,
     "sourceId": 10136001,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
