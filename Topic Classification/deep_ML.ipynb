{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10136001,"sourceType":"datasetVersion","datasetId":6255630}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, TFBertModel\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Input\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:22:26.000887Z","iopub.execute_input":"2024-12-11T15:22:26.001691Z","iopub.status.idle":"2024-12-11T15:22:44.670325Z","shell.execute_reply.started":"2024-12-11T15:22:26.001653Z","shell.execute_reply":"2024-12-11T15:22:44.669617Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:22:44.671875Z","iopub.execute_input":"2024-12-11T15:22:44.672410Z","iopub.status.idle":"2024-12-11T15:22:45.724387Z","shell.execute_reply.started":"2024-12-11T15:22:44.672375Z","shell.execute_reply":"2024-12-11T15:22:45.723265Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/tubes-nlp/seq2seq_data.csv\")\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:22:45.725683Z","iopub.execute_input":"2024-12-11T15:22:45.725984Z","iopub.status.idle":"2024-12-11T15:22:46.500293Z","shell.execute_reply.started":"2024-12-11T15:22:45.725956Z","shell.execute_reply":"2024-12-11T15:22:46.499407Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        topic_category                                      original_text  \\\n0                  9.0                       what makes friendship click?   \n1                  2.0                      why does zebras have stripes?   \n2                  4.0           what did the itsy bitsy sipder climb up?   \n3                  4.0  what is the difference between a bachelors and...   \n4                  3.0                              why do women get pms?   \n...                ...                                                ...   \n174712             9.0  imperative: tell me what guys only guys must do!    \n174713             9.0  tell me the story of any fantasy figure i'd ch...   \n174714             8.0           imperative: reveal a secret about life.    \n174715             6.0  imperative: demande à domenech ce qu'il en est...   \n174716             5.0          tell me the low sounds that a cat makes!    \n\n                                           base_word_text  \n0                             what make friendship click   \n1                                       why zebra stripe   \n2                        what itsy bitsy sipder climb up   \n3       what difference between bachelor and master de...  \n4                                       why woman get pm   \n...                                                   ...  \n174712                    tell me what guy only guy must   \n174713    tell me story of any fantasy figure i d choose   \n174714                          reveal secret about life   \n174715   demande à domenech ce quil en est de son méti...  \n174716                   tell me low sound that cat make   \n\n[174717 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_category</th>\n      <th>original_text</th>\n      <th>base_word_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.0</td>\n      <td>what makes friendship click?</td>\n      <td>what make friendship click</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>why does zebras have stripes?</td>\n      <td>why zebra stripe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>what did the itsy bitsy sipder climb up?</td>\n      <td>what itsy bitsy sipder climb up</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>what is the difference between a bachelors and...</td>\n      <td>what difference between bachelor and master de...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>why do women get pms?</td>\n      <td>why woman get pm</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>174712</th>\n      <td>9.0</td>\n      <td>imperative: tell me what guys only guys must do!</td>\n      <td>tell me what guy only guy must</td>\n    </tr>\n    <tr>\n      <th>174713</th>\n      <td>9.0</td>\n      <td>tell me the story of any fantasy figure i'd ch...</td>\n      <td>tell me story of any fantasy figure i d choose</td>\n    </tr>\n    <tr>\n      <th>174714</th>\n      <td>8.0</td>\n      <td>imperative: reveal a secret about life.</td>\n      <td>reveal secret about life</td>\n    </tr>\n    <tr>\n      <th>174715</th>\n      <td>6.0</td>\n      <td>imperative: demande à domenech ce qu'il en est...</td>\n      <td>demande à domenech ce quil en est de son méti...</td>\n    </tr>\n    <tr>\n      <th>174716</th>\n      <td>5.0</td>\n      <td>tell me the low sounds that a cat makes!</td>\n      <td>tell me low sound that cat make</td>\n    </tr>\n  </tbody>\n</table>\n<p>174717 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"data.dropna(inplace=True)\ndata.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:22:46.502596Z","iopub.execute_input":"2024-12-11T15:22:46.503406Z","iopub.status.idle":"2024-12-11T15:22:46.554932Z","shell.execute_reply.started":"2024-12-11T15:22:46.503359Z","shell.execute_reply":"2024-12-11T15:22:46.554060Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"topic_category    0\noriginal_text     0\nbase_word_text    0\ndtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk\n\n# Ensure you have the necessary NLTK data files\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Define stopwords and punctuation\nstop_words = set(stopwords.words('english'))\nstop_words.update([\"imperative\", \"declarative\"])\npunctuation = string.punctuation\n\n# Function to preprocess text\ndef preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', punctuation))\n    # Tokenize text\n    words = word_tokenize(text)\n    # Remove stopwords\n    words = [word for word in words if word not in stop_words]\n    return ' '.join(words)\n\n# Apply the preprocessing function to the 'original_text' column\ndata['processed_text'] = data['original_text'].apply(preprocess_text)\ndata[['original_text', 'processed_text']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:22:46.556240Z","iopub.execute_input":"2024-12-11T15:22:46.557012Z","iopub.status.idle":"2024-12-11T15:23:03.507746Z","shell.execute_reply.started":"2024-12-11T15:22:46.556950Z","shell.execute_reply":"2024-12-11T15:23:03.506848Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                       original_text  \\\n0                       what makes friendship click?   \n1                      why does zebras have stripes?   \n2           what did the itsy bitsy sipder climb up?   \n3  what is the difference between a bachelors and...   \n4                              why do women get pms?   \n\n                        processed_text  \n0               makes friendship click  \n1                       zebras stripes  \n2              itsy bitsy sipder climb  \n3  difference bachelors masters degree  \n4                        women get pms  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>processed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what makes friendship click?</td>\n      <td>makes friendship click</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>why does zebras have stripes?</td>\n      <td>zebras stripes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what did the itsy bitsy sipder climb up?</td>\n      <td>itsy bitsy sipder climb</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what is the difference between a bachelors and...</td>\n      <td>difference bachelors masters degree</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>why do women get pms?</td>\n      <td>women get pms</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"markdown","source":"##","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Tokenize and pad sequences\ntokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\ntokenizer.fit_on_texts(data['processed_text'])\nX = tokenizer.texts_to_sequences(data['processed_text'])\nX = pad_sequences(X, maxlen=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:01:44.986295Z","iopub.execute_input":"2024-12-10T03:01:44.987418Z","iopub.status.idle":"2024-12-10T03:01:48.993422Z","shell.execute_reply.started":"2024-12-10T03:01:44.987381Z","shell.execute_reply":"2024-12-10T03:01:48.992664Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load pre-trained GloVe embeddings\nembedding_index = {}\nwith open('/kaggle/input/tubes-nlp/glove.6B.100d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embedding_index[word] = coefs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:01:48.994990Z","iopub.execute_input":"2024-12-10T03:01:48.995363Z","iopub.status.idle":"2024-12-10T03:01:59.170063Z","shell.execute_reply.started":"2024-12-10T03:01:48.995327Z","shell.execute_reply":"2024-12-10T03:01:59.169364Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Create embedding matrix\nword_index = tokenizer.word_index\nembedding_matrix = np.zeros((5000, 100))\nfor word, i in word_index.items():\n    if i < 5000:\n        embedding_vector = embedding_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:01:59.171271Z","iopub.execute_input":"2024-12-10T03:01:59.171533Z","iopub.status.idle":"2024-12-10T03:01:59.194901Z","shell.execute_reply.started":"2024-12-10T03:01:59.171506Z","shell.execute_reply":"2024-12-10T03:01:59.194276Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### BERT Embedding","metadata":{}},{"cell_type":"code","source":"# Load BERT tokenizer and model\ntokenizer_bert_embedding = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_embedding_model = TFBertModel.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:23:08.444356Z","iopub.execute_input":"2024-12-11T15:23:08.444688Z","iopub.status.idle":"2024-12-11T15:23:10.119864Z","shell.execute_reply.started":"2024-12-11T15:23:08.444660Z","shell.execute_reply":"2024-12-11T15:23:10.118920Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Tokenize input text\n\nchunk_size = 30  # Adjust based on available memory\ntexts = list(data['processed_text'])\nnum_chunks = (len(texts)) // chunk_size + 1\n\nall_embeddings = []\nfor chunk_idx in tqdm(range(num_chunks)):\n    chunk_texts = texts[chunk_idx * chunk_size:(chunk_idx + 1) * chunk_size]\n    inputs = tokenizer_bert_embedding(chunk_texts, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n    outputs = bert_embedding_model(**inputs)\n    all_embeddings.append(outputs.last_hidden_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:23:10.121429Z","iopub.execute_input":"2024-12-11T15:23:10.121688Z","iopub.status.idle":"2024-12-11T15:41:56.515010Z","shell.execute_reply.started":"2024-12-11T15:23:10.121662Z","shell.execute_reply":"2024-12-11T15:41:56.514081Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 5797/5797 [18:46<00:00,  5.15it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T12:54:01.749098Z","iopub.execute_input":"2024-12-11T12:54:01.749448Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### BERT","metadata":{}},{"cell_type":"code","source":"## BERT\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\n\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:01:28.412884Z","iopub.execute_input":"2024-12-11T13:01:28.413272Z","iopub.status.idle":"2024-12-11T13:01:28.760758Z","shell.execute_reply.started":"2024-12-11T13:01:28.413242Z","shell.execute_reply":"2024-12-11T13:01:28.760098Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class TopicClassificationDataset(Dataset):\n    \"\"\"Custom PyTorch Dataset for topic classification\"\"\"\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        # Handle both integer and list indexing\n        if isinstance(idx, list):\n            texts = [self.texts[i] for i in idx]\n            labels = [self.labels[i] for i in idx]\n        else:\n            texts = [self.texts[idx]]\n            labels = [self.labels[idx]]\n        \n        # Batch encoding\n        encodings = self.tokenizer(\n            texts,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encodings['input_ids'].squeeze(),\n            'attention_mask': encodings['attention_mask'].squeeze(),\n            'labels': torch.tensor(labels, dtype=torch.long).squeeze()\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:01:29.191274Z","iopub.execute_input":"2024-12-11T13:01:29.191598Z","iopub.status.idle":"2024-12-11T13:01:29.198493Z","shell.execute_reply.started":"2024-12-11T13:01:29.191570Z","shell.execute_reply":"2024-12-11T13:01:29.197585Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## One Hot Encoding","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny = to_categorical([label - 1 for label in data['topic_category'].values], num_classes=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:42:52.141356Z","iopub.execute_input":"2024-12-11T15:42:52.142275Z","iopub.status.idle":"2024-12-11T15:42:52.200036Z","shell.execute_reply.started":"2024-12-11T15:42:52.142235Z","shell.execute_reply":"2024-12-11T15:42:52.199117Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Data Splitting","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T05:25:27.647332Z","iopub.execute_input":"2024-12-10T05:25:27.647731Z","iopub.status.idle":"2024-12-10T05:25:27.652167Z","shell.execute_reply.started":"2024-12-10T05:25:27.647700Z","shell.execute_reply":"2024-12-10T05:25:27.651289Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### Bert Embedding","metadata":{}},{"cell_type":"code","source":"y_bert_embedding = [y[chunk_idx * chunk_size:(chunk_idx + 1) * chunk_size] for chunk_idx in range (num_chunks)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:42:54.908858Z","iopub.execute_input":"2024-12-11T15:42:54.909232Z","iopub.status.idle":"2024-12-11T15:42:54.916382Z","shell.execute_reply.started":"2024-12-11T15:42:54.909200Z","shell.execute_reply":"2024-12-11T15:42:54.915389Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"split_idx = int(num_chunks * 0.8) \n\nX_train_bert_embedding, X_test_bert_embedding = all_embeddings[:split_idx], all_embeddings[split_idx:-1]\ny_train_bert_embedding, y_test_bert_embedding = y_bert_embedding[:split_idx], y_bert_embedding[split_idx:-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:42:56.054324Z","iopub.execute_input":"2024-12-11T15:42:56.054705Z","iopub.status.idle":"2024-12-11T15:42:56.059717Z","shell.execute_reply.started":"2024-12-11T15:42:56.054672Z","shell.execute_reply":"2024-12-11T15:42:56.058837Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### BERT","metadata":{}},{"cell_type":"code","source":"sample_ratio = 0.05  \ninstances_per_class = int(len(data) * sample_ratio / 10)  # Calculate instances per class\n\n# Sample data equally for each class\nsample_data = data.groupby('topic_category').sample(n=instances_per_class, random_state=42)\n\n# Ensure balanced test set\nprint(sample_data['topic_category'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:01:34.731461Z","iopub.execute_input":"2024-12-11T13:01:34.731844Z","iopub.status.idle":"2024-12-11T13:01:34.803018Z","shell.execute_reply.started":"2024-12-11T13:01:34.731813Z","shell.execute_reply":"2024-12-11T13:01:34.802000Z"}},"outputs":[{"name":"stdout","text":"topic_category\n1.0     869\n2.0     869\n3.0     869\n4.0     869\n5.0     869\n6.0     869\n7.0     869\n8.0     869\n9.0     869\n10.0    869\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(list(sample_data['processed_text']), [int(label - 1) for label in sample_data['topic_category'].values], test_size=0.2, random_state=42) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:02:07.327812Z","iopub.execute_input":"2024-12-11T13:02:07.328581Z","iopub.status.idle":"2024-12-11T13:02:07.341877Z","shell.execute_reply.started":"2024-12-11T13:02:07.328546Z","shell.execute_reply":"2024-12-11T13:02:07.340878Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Prepare datasets\ntrain_dataset = TopicClassificationDataset(X_train_bert, y_train_bert, bert_tokenizer)\nval_dataset = TopicClassificationDataset(X_test_bert, y_test_bert, bert_tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:02:15.726164Z","iopub.execute_input":"2024-12-11T13:02:15.726528Z","iopub.status.idle":"2024-12-11T13:02:15.732027Z","shell.execute_reply.started":"2024-12-11T13:02:15.726499Z","shell.execute_reply":"2024-12-11T13:02:15.731014Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Model Development","metadata":{}},{"cell_type":"markdown","source":"## Long Short-Term Memory (LSTM)","metadata":{}},{"cell_type":"code","source":"lstm_model = Sequential()\nlstm_model.add(Embedding(input_dim=5000, output_dim=100, weights=[embedding_matrix], input_length=100, trainable=False))\nlstm_model.add(Bidirectional(tf.keras.layers.LSTM(200)))\nlstm_model.add(Dense(100, activation='relu'))\nlstm_model.add(Dense(10, activation='softmax'))\n\nlstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:08:19.437865Z","iopub.execute_input":"2024-12-10T03:08:19.438309Z","iopub.status.idle":"2024-12-10T03:08:19.469353Z","shell.execute_reply.started":"2024-12-10T03:08:19.438277Z","shell.execute_reply":"2024-12-10T03:08:19.468468Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"lstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:08:19.737045Z","iopub.execute_input":"2024-12-10T03:08:19.737405Z","iopub.status.idle":"2024-12-10T03:14:28.777590Z","shell.execute_reply.started":"2024-12-10T03:08:19.737376Z","shell.execute_reply":"2024-12-10T03:14:28.776760Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n2174/2174 - 39s - 18ms/step - accuracy: 0.5550 - loss: 1.3731 - val_accuracy: 0.5772 - val_loss: 1.3020\nEpoch 2/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.5917 - loss: 1.2566 - val_accuracy: 0.5907 - val_loss: 1.2625\nEpoch 3/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.6076 - loss: 1.2044 - val_accuracy: 0.5987 - val_loss: 1.2410\nEpoch 4/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.6252 - loss: 1.1439 - val_accuracy: 0.6004 - val_loss: 1.2390\nEpoch 5/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.6409 - loss: 1.0922 - val_accuracy: 0.6041 - val_loss: 1.2291\nEpoch 6/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.6566 - loss: 1.0356 - val_accuracy: 0.6051 - val_loss: 1.2451\nEpoch 7/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.6757 - loss: 0.9729 - val_accuracy: 0.6039 - val_loss: 1.2592\nEpoch 8/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.6944 - loss: 0.9114 - val_accuracy: 0.5998 - val_loss: 1.2902\nEpoch 9/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.7145 - loss: 0.8467 - val_accuracy: 0.5987 - val_loss: 1.3501\nEpoch 10/10\n2174/2174 - 37s - 17ms/step - accuracy: 0.7356 - loss: 0.7810 - val_accuracy: 0.5970 - val_loss: 1.4189\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f79ac51eec0>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"### LSTM using BERT Embedding","metadata":{}},{"cell_type":"code","source":"lstm_model_bert = Sequential()\nlstm_model_bert.add(Input(shape=(None, 768))) # 768 is the hidden size of BERT-base\nlstm_model_bert.add(Bidirectional(tf.keras.layers.LSTM(200)))\nlstm_model_bert.add(Dense(100, activation='relu'))\nlstm_model_bert.add(Dense(10, activation='softmax'))\n\nlstm_model_bert.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:43:05.359113Z","iopub.execute_input":"2024-12-11T15:43:05.359826Z","iopub.status.idle":"2024-12-11T15:43:05.551039Z","shell.execute_reply.started":"2024-12-11T15:43:05.359791Z","shell.execute_reply":"2024-12-11T15:43:05.550335Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"lstm_model_bert.fit(X_train_bert_embedding, y_train_bert_embedding, epochs=2, batch_size=chunk_size, validation_data=(X_test_bert_embedding, y_test_bert_embedding), verbose=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:43:05.826736Z","iopub.execute_input":"2024-12-11T15:43:05.827080Z","iopub.status.idle":"2024-12-11T15:44:32.186880Z","shell.execute_reply.started":"2024-12-11T15:43:05.827047Z","shell.execute_reply":"2024-12-11T15:44:32.185842Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/2\n1/1 - 34s - 34s/step - accuracy: 0.0333 - loss: 2.3634 - val_accuracy: 0.0667 - val_loss: 2.3802\nEpoch 2/2\n1/1 - 18s - 18s/step - accuracy: 0.6667 - loss: 1.8155 - val_accuracy: 0.1000 - val_loss: 2.4250\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cfb96046a10>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Convolutional Neural Networks (CNNs)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n\ncnn_model = Sequential()\ncnn_model.add(Embedding(input_dim=5000, output_dim=100, input_length=100))\ncnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\ncnn_model.add(GlobalMaxPooling1D())\ncnn_model.add(Dense(50, activation='relu'))\ncnn_model.add(Dropout(0.5))\ncnn_model.add(Dense(10, activation='softmax'))\n\n# Compile model\ncnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:06:22.780804Z","iopub.execute_input":"2024-12-10T03:06:22.781178Z","iopub.status.idle":"2024-12-10T03:06:22.797596Z","shell.execute_reply.started":"2024-12-10T03:06:22.781146Z","shell.execute_reply":"2024-12-10T03:06:22.796868Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Train model\ncnn_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:06:23.017446Z","iopub.execute_input":"2024-12-10T03:06:23.018023Z","iopub.status.idle":"2024-12-10T03:07:29.422907Z","shell.execute_reply.started":"2024-12-10T03:06:23.017994Z","shell.execute_reply":"2024-12-10T03:07:29.422074Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n2174/2174 - 11s - 5ms/step - accuracy: 0.5028 - loss: 1.5549 - val_accuracy: 0.5926 - val_loss: 1.2849\nEpoch 2/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.6032 - loss: 1.2847 - val_accuracy: 0.6032 - val_loss: 1.2405\nEpoch 3/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.6289 - loss: 1.1874 - val_accuracy: 0.6057 - val_loss: 1.2377\nEpoch 4/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.6536 - loss: 1.0931 - val_accuracy: 0.6076 - val_loss: 1.2426\nEpoch 5/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.6798 - loss: 1.0028 - val_accuracy: 0.6060 - val_loss: 1.2719\nEpoch 6/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.7055 - loss: 0.9130 - val_accuracy: 0.6043 - val_loss: 1.3517\nEpoch 7/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.7288 - loss: 0.8282 - val_accuracy: 0.6004 - val_loss: 1.4379\nEpoch 8/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.7505 - loss: 0.7557 - val_accuracy: 0.5974 - val_loss: 1.5291\nEpoch 9/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.7678 - loss: 0.6999 - val_accuracy: 0.5939 - val_loss: 1.6744\nEpoch 10/10\n2174/2174 - 6s - 3ms/step - accuracy: 0.7819 - loss: 0.6510 - val_accuracy: 0.5936 - val_loss: 1.7490\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f79c02f0040>"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:02:32.076350Z","iopub.execute_input":"2024-12-11T13:02:32.076701Z","iopub.status.idle":"2024-12-11T13:02:32.438959Z","shell.execute_reply.started":"2024-12-11T13:02:32.076671Z","shell.execute_reply":"2024-12-11T13:02:32.437811Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"bert_model.config.problem_type = \"single_label_classification\"  # For multi-class classification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:02:36.524560Z","iopub.execute_input":"2024-12-11T13:02:36.524922Z","iopub.status.idle":"2024-12-11T13:02:36.529269Z","shell.execute_reply.started":"2024-12-11T13:02:36.524892Z","shell.execute_reply":"2024-12-11T13:02:36.528365Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Optimizer\noptimizer = AdamW(bert_model.parameters(), lr=2e-5)\nepochs = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:02:37.227488Z","iopub.execute_input":"2024-12-11T13:02:37.227796Z","iopub.status.idle":"2024-12-11T13:02:37.237260Z","shell.execute_reply.started":"2024-12-11T13:02:37.227770Z","shell.execute_reply":"2024-12-11T13:02:37.236282Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"len(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:02:39.553026Z","iopub.execute_input":"2024-12-11T13:02:39.553389Z","iopub.status.idle":"2024-12-11T13:02:39.559158Z","shell.execute_reply.started":"2024-12-11T13:02:39.553361Z","shell.execute_reply":"2024-12-11T13:02:39.558248Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"435"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Training loop\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbert_model.to(device)\n\nfor epoch in range(epochs):\n    bert_model.train()\n    total_train_loss = 0\n\n    for i, batch in enumerate(train_loader):\n        optimizer.zero_grad()\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        outputs = bert_model(\n            input_ids, \n            attention_mask=attention_mask, \n            labels=labels\n        )\n        \n        loss = outputs.loss\n        total_train_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        # print(f\"training batch-{i+1}, epoch-{epoch+1}\")\n    # Validation\n    bert_model.eval()\n    total_val_loss = 0\n    predictions, true_labels = [], []\n    \n    with torch.no_grad():\n        for j,batch in enumerate(val_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = bert_model(\n                input_ids, \n                attention_mask=attention_mask, \n                labels=labels\n            )\n            \n            total_val_loss += outputs.loss.item()\n            \n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            \n            predictions.extend(preds.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n            # print(f\"validation batch-{j+1}, epoch-{epoch+1}\")\n    \n    # Print epoch summary\n    avg_train_loss = total_train_loss / len(train_loader)\n    avg_val_loss = total_val_loss / len(val_loader)\n    print(f'Epoch {epoch+1}/{epochs}')\n    print(f'Average training loss: {avg_train_loss:.4f}')\n    print(f'Average validation loss: {avg_val_loss:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:02:42.227212Z","iopub.execute_input":"2024-12-11T13:02:42.227583Z","iopub.status.idle":"2024-12-11T13:11:34.679108Z","shell.execute_reply.started":"2024-12-11T13:02:42.227552Z","shell.execute_reply":"2024-12-11T13:11:34.678135Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\nAverage training loss: 1.5310\nAverage validation loss: 1.2267\nEpoch 2/3\nAverage training loss: 1.0109\nAverage validation loss: 1.2376\nEpoch 3/3\nAverage training loss: 0.7431\nAverage validation loss: 1.2922\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"## LSTM","metadata":{}},{"cell_type":"code","source":"lstm_predictions = lstm_model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lstm_predictions_processed = np.zeros_like(lstm_predictions)\nlstm_predictions_processed[np.arange(len(lstm_predictions)), np.argmax(lstm_predictions, axis=1)] = 1\nlstm_predictions_processed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:16:15.604276Z","iopub.execute_input":"2024-12-10T03:16:15.604531Z","iopub.status.idle":"2024-12-10T03:16:15.612873Z","shell.execute_reply.started":"2024-12-10T03:16:15.604507Z","shell.execute_reply":"2024-12-10T03:16:15.612170Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"print(\"Classification Report:\\n\", classification_report(y_test, lstm_predictions_processed))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:16:15.613819Z","iopub.execute_input":"2024-12-10T03:16:15.614071Z","iopub.status.idle":"2024-12-10T03:16:15.673787Z","shell.execute_reply.started":"2024-12-10T03:16:15.614046Z","shell.execute_reply":"2024-12-10T03:16:15.672927Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.52      0.45      0.48      3408\n           1       0.52      0.66      0.58      3585\n           2       0.63      0.64      0.64      3403\n           3       0.46      0.43      0.44      3523\n           4       0.76      0.76      0.76      3517\n           5       0.78      0.72      0.75      3530\n           6       0.56      0.40      0.47      3469\n           7       0.55      0.59      0.57      3538\n           8       0.57      0.64      0.61      3358\n           9       0.62      0.67      0.64      3451\n\n   micro avg       0.60      0.60      0.60     34782\n   macro avg       0.60      0.60      0.59     34782\nweighted avg       0.60      0.60      0.59     34782\n samples avg       0.60      0.60      0.60     34782\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"### LSTM using BERT Embedding","metadata":{}},{"cell_type":"code","source":"lstm_bert_predictions = None\nfor i in tqdm(range (len(X_test_bert_embedding))):\n    lstm_bert_prediction = lstm_model_bert.predict(X_test_bert_embedding[i], verbose=0)\n    if i == 0:\n        lstm_bert_predictions = lstm_bert_prediction\n    else:\n        lstm_bert_predictions = np.vstack((lstm_bert_predictions, lstm_bert_prediction))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:09:42.686871Z","iopub.execute_input":"2024-12-11T15:09:42.687868Z","iopub.status.idle":"2024-12-11T15:10:53.389180Z","shell.execute_reply.started":"2024-12-11T15:09:42.687813Z","shell.execute_reply":"2024-12-11T15:10:53.388172Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1159/1159 [01:10<00:00, 16.39it/s]\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"lstm_bert_predictions_processed = np.zeros_like(lstm_bert_predictions)\nlstm_bert_predictions_processed[np.arange(len(lstm_bert_predictions)), np.argmax(lstm_bert_predictions, axis=1)] = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:10:53.390796Z","iopub.execute_input":"2024-12-11T15:10:53.391097Z","iopub.status.idle":"2024-12-11T15:10:53.397278Z","shell.execute_reply.started":"2024-12-11T15:10:53.391068Z","shell.execute_reply":"2024-12-11T15:10:53.396505Z"},"scrolled":true},"outputs":[],"execution_count":52},{"cell_type":"code","source":"y_test_bert_embedding_unbatch = None\nfor i in range(len(y_test_bert_embedding)):\n    if i ==0:\n        y_test_bert_embedding_unbatch = y_test_bert_embedding[0]\n    else:\n        y_test_bert_embedding_unbatch = np.vstack((y_test_bert_embedding_unbatch, y_test_bert_embedding[i]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:10:53.398217Z","iopub.execute_input":"2024-12-11T15:10:53.398510Z","iopub.status.idle":"2024-12-11T15:10:53.556951Z","shell.execute_reply.started":"2024-12-11T15:10:53.398484Z","shell.execute_reply":"2024-12-11T15:10:53.556215Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"print(\"Classification Report:\\n\", classification_report(y_test_bert_embedding_unbatch, lstm_bert_predictions_processed))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:10:53.558454Z","iopub.execute_input":"2024-12-11T15:10:53.558745Z","iopub.status.idle":"2024-12-11T15:10:53.607636Z","shell.execute_reply.started":"2024-12-11T15:10:53.558718Z","shell.execute_reply":"2024-12-11T15:10:53.606906Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.31      0.00      0.00      3848\n           1       0.12      0.50      0.20      3478\n           2       0.17      0.51      0.25      3558\n           3       0.14      0.08      0.10      3409\n           4       0.62      0.04      0.07      3443\n           5       0.36      0.01      0.02      3832\n           6       0.12      0.17      0.15      1974\n           7       0.17      0.04      0.06      4016\n           8       0.26      0.25      0.26      3439\n           9       0.28      0.02      0.04      3773\n\n   micro avg       0.16      0.16      0.16     34770\n   macro avg       0.26      0.16      0.12     34770\nweighted avg       0.26      0.16      0.11     34770\n samples avg       0.16      0.16      0.16     34770\n\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"## CNN","metadata":{}},{"cell_type":"code","source":"cnn_predictions = cnn_model.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:07:50.218921Z","iopub.execute_input":"2024-12-10T03:07:50.219752Z","iopub.status.idle":"2024-12-10T03:07:52.492794Z","shell.execute_reply.started":"2024-12-10T03:07:50.219717Z","shell.execute_reply":"2024-12-10T03:07:52.492058Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"cnn_predictions_processed = np.zeros_like(cnn_predictions)\ncnn_predictions_processed[np.arange(len(cnn_predictions)), np.argmax(cnn_predictions, axis=1)] = 1\ncnn_predictions_processed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:07:52.494454Z","iopub.execute_input":"2024-12-10T03:07:52.494757Z","iopub.status.idle":"2024-12-10T03:07:52.503013Z","shell.execute_reply.started":"2024-12-10T03:07:52.494730Z","shell.execute_reply":"2024-12-10T03:07:52.502276Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"print(\"Classification Report:\\n\", classification_report(y_test, cnn_predictions_processed))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:07:55.393367Z","iopub.execute_input":"2024-12-10T03:07:55.393694Z","iopub.status.idle":"2024-12-10T03:07:55.448590Z","shell.execute_reply.started":"2024-12-10T03:07:55.393664Z","shell.execute_reply":"2024-12-10T03:07:55.447664Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.47      0.49      0.48      3408\n           1       0.52      0.64      0.57      3585\n           2       0.61      0.66      0.63      3403\n           3       0.50      0.40      0.45      3523\n           4       0.76      0.75      0.76      3517\n           5       0.80      0.71      0.75      3530\n           6       0.52      0.42      0.46      3469\n           7       0.58      0.57      0.57      3538\n           8       0.55      0.65      0.59      3358\n           9       0.64      0.65      0.65      3451\n\n   micro avg       0.59      0.59      0.59     34782\n   macro avg       0.60      0.59      0.59     34782\nweighted avg       0.60      0.59      0.59     34782\n samples avg       0.59      0.59      0.59     34782\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"def predict_topic(text, model, tokenizer, max_length=128):\n    \"\"\"\n    Predict topic for a single text input\n    \n    Args:\n        text (str): Input text to classify\n        model (BertForSequenceClassification): Trained BERT model\n        tokenizer (BertTokenizer): Tokenizer used during training\n        max_length (int): Maximum sequence length\n    \n    Returns:\n        Predicted topic label (integer)\n    \"\"\"\n    model.eval()\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    \n    # Encode the text\n    encoding = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        prediction = torch.argmax(logits, dim=1)\n    \n    return prediction.cpu().item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:13:29.087144Z","iopub.execute_input":"2024-12-11T13:13:29.088071Z","iopub.status.idle":"2024-12-11T13:13:29.094024Z","shell.execute_reply.started":"2024-12-11T13:13:29.088031Z","shell.execute_reply":"2024-12-11T13:13:29.093126Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"bert_predictions = []\nfor test_text in tqdm(X_test_bert):\n        predicted_topic = predict_topic(\n            test_text, bert_model, bert_tokenizer\n        )\n        bert_predictions.append(predicted_topic)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:13:29.943255Z","iopub.execute_input":"2024-12-11T13:13:29.943577Z","iopub.status.idle":"2024-12-11T13:13:53.156835Z","shell.execute_reply.started":"2024-12-11T13:13:29.943553Z","shell.execute_reply":"2024-12-11T13:13:53.155904Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1738/1738 [00:23<00:00, 74.90it/s]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"print(\"Classification Report:\\n\", classification_report(y_test_bert, bert_predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:13:53.158267Z","iopub.execute_input":"2024-12-11T13:13:53.158561Z","iopub.status.idle":"2024-12-11T13:13:53.175869Z","shell.execute_reply.started":"2024-12-11T13:13:53.158534Z","shell.execute_reply":"2024-12-11T13:13:53.174999Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.59      0.49      0.54       184\n           1       0.61      0.66      0.64       193\n           2       0.68      0.77      0.72       160\n           3       0.50      0.31      0.38       179\n           4       0.70      0.75      0.73       158\n           5       0.80      0.77      0.79       179\n           6       0.55      0.45      0.49       167\n           7       0.63      0.62      0.63       186\n           8       0.51      0.78      0.62       167\n           9       0.69      0.67      0.68       165\n\n    accuracy                           0.63      1738\n   macro avg       0.63      0.63      0.62      1738\nweighted avg       0.63      0.63      0.62      1738\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"save_directory = './fine_tuned_bert_model_v2'\n\n# Save the fine-tuned model and tokenizer\nbert_model.save_pretrained(save_directory)\nbert_tokenizer.save_pretrained(save_directory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T13:13:53.176703Z","iopub.execute_input":"2024-12-11T13:13:53.176931Z","iopub.status.idle":"2024-12-11T13:13:54.827762Z","shell.execute_reply.started":"2024-12-11T13:13:53.176909Z","shell.execute_reply":"2024-12-11T13:13:54.826738Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_bert_model_v2/tokenizer_config.json',\n './fine_tuned_bert_model_v2/special_tokens_map.json',\n './fine_tuned_bert_model_v2/vocab.txt',\n './fine_tuned_bert_model_v2/added_tokens.json')"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}